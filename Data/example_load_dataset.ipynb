{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minij\\OneDrive\\Escritorio\\Master\\Spring 2023\\Development of improved prediction methods for B cell epitopes prediction\\Data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minij\\anaconda3\\envs\\special_course\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from make_dataset import Discotope_Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test dataset: 24 PDBs\n",
      "Length of test dataset (af2): 24 PDBs\n"
     ]
    }
   ],
   "source": [
    "# Experimental PDB dataset\n",
    "#train_set = torch.load(\"data/processed/new/bp3_train_seqs_solved/dataset.pt\")\n",
    "#valid_set = torch.load(\"data/processed/new/bp3_valid_seqs_solved/dataset.pt\")\n",
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "test_set = torch.load(\"SN_DT_SEMA_test_filtered_solved/dataset.pt\")\n",
    "test_set_af2 = torch.load(\"SN_DT_SEMA_test_filtered_af2/dataset.pt\")\n",
    "print(f\"Length of test dataset: {len(test_set)} PDBs\")\n",
    "print(f\"Length of test dataset (af2): {len(test_set_af2)} PDBs\")\n",
    "\n",
    "# train_set = torch.load(\"bp3_train_seqs_solved/dataset.pt\")\n",
    "# print(f\"Length of train dataset: {len(train_set)} PDBs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dfs_test = []\n",
    "for i in range(0, len(test_set), 1):\n",
    "    sample = test_set[i]\n",
    "    df_sample = sample['df_stats']\n",
    "    if(df_sample['rsa'].isna().any() == True):\n",
    "        df_sample['epitope'] = sample['y_arr'].astype(bool)\n",
    "        stats_dfs_test.append(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation loading\n",
    "\n",
    "val_set = torch.load(\"bp3_valid_seqs_solved/dataset.pt\")\n",
    "val_set_af2 = torch.load(\"bp3_valid_seqs_af2/dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_pdb = []\n",
    "id_af2 = []\n",
    "for i in range(0, len(val_set), 1):\n",
    "    sample_af2 = val_set_af2[i]\n",
    "    sample_pdb = val_set[i]\n",
    "    id_pdb.append(sample_af2['pdb_id'])\n",
    "    id_af2.append(sample_af2['pdb_id'])\n",
    "\n",
    "id_pdb == id_af2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of validation dataset (solved): 281 PDBs\n",
      "Length of validation dataset (af2): 281 PDBs\n"
     ]
    }
   ],
   "source": [
    "# Validation loading\n",
    "\n",
    "val_set = torch.load(\"bp3_valid_seqs_solved/dataset.pt\")\n",
    "val_set_af2 = torch.load(\"bp3_valid_seqs_af2/dataset.pt\")\n",
    "print(f\"Length of validation dataset (solved): {len(val_set)} PDBs\")\n",
    "print(f\"Length of validation dataset (af2): {len(val_set_af2)} PDBs\")\n",
    "\n",
    "stats_dfs_test = []\n",
    "for i in range(0, len(val_set), 1):\n",
    "    sample = val_set[i]\n",
    "    df_sample = sample['df_stats']\n",
    "    if(sample['df_stats']['rsa'].isna().any() == True):\n",
    "        df_sample['epitope'] = sample['y_arr'].astype(bool)\n",
    "        stats_dfs_test.append(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pdb_id', 'pdb_fp', 'X_arr', 'y_arr', 'df_stats', 'length', 'pLDDTs', 'RSAs', 'sequence_str', 'pdb_seq', 'feature_idxs', 'struc_type'])\n"
     ]
    }
   ],
   "source": [
    "# Load one sample\n",
    "sample = test_set[3]\n",
    "print(sample.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['y_arr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: (419, 536)\n",
      "feature_columns: {'IF_tensor': range(0, 512), 'sequence': range(512, 532), 'pLDDTs': range(532, 533), 'lengths': range(533, 534), 'struc_type': range(534, 535), 'RSAs': range(535, 536)}\n",
      "targets: (419,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features: {sample['X_arr'].shape}\")\n",
    "print(f\"feature_columns: {sample['feature_idxs']}\")\n",
    "print(f\"targets: {sample['y_arr'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>idx</th>\n",
       "      <th>residue</th>\n",
       "      <th>res_idx</th>\n",
       "      <th>rsa</th>\n",
       "      <th>diam</th>\n",
       "      <th>gyrrad</th>\n",
       "      <th>pLDDTs</th>\n",
       "      <th>length</th>\n",
       "      <th>struc_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6wjl_G</td>\n",
       "      <td>1</td>\n",
       "      <td>s</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>114.031616</td>\n",
       "      <td>32.728819</td>\n",
       "      <td>100.0</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6wjl_G</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>0.247985</td>\n",
       "      <td>114.031616</td>\n",
       "      <td>32.728819</td>\n",
       "      <td>100.0</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6wjl_G</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>0.435171</td>\n",
       "      <td>114.031616</td>\n",
       "      <td>32.728819</td>\n",
       "      <td>100.0</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6wjl_G</td>\n",
       "      <td>4</td>\n",
       "      <td>e</td>\n",
       "      <td>4</td>\n",
       "      <td>0.379443</td>\n",
       "      <td>114.031616</td>\n",
       "      <td>32.728819</td>\n",
       "      <td>100.0</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6wjl_G</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013140</td>\n",
       "      <td>114.031616</td>\n",
       "      <td>32.728819</td>\n",
       "      <td>100.0</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>6wjl_G</td>\n",
       "      <td>415</td>\n",
       "      <td>l</td>\n",
       "      <td>415</td>\n",
       "      <td>0.495708</td>\n",
       "      <td>114.031616</td>\n",
       "      <td>32.728819</td>\n",
       "      <td>100.0</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>6wjl_G</td>\n",
       "      <td>416</td>\n",
       "      <td>g</td>\n",
       "      <td>416</td>\n",
       "      <td>0.135044</td>\n",
       "      <td>114.031616</td>\n",
       "      <td>32.728819</td>\n",
       "      <td>100.0</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>6wjl_G</td>\n",
       "      <td>417</td>\n",
       "      <td>h</td>\n",
       "      <td>417</td>\n",
       "      <td>0.583213</td>\n",
       "      <td>114.031616</td>\n",
       "      <td>32.728819</td>\n",
       "      <td>100.0</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>6wjl_G</td>\n",
       "      <td>418</td>\n",
       "      <td>d</td>\n",
       "      <td>418</td>\n",
       "      <td>0.329285</td>\n",
       "      <td>114.031616</td>\n",
       "      <td>32.728819</td>\n",
       "      <td>100.0</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>6wjl_G</td>\n",
       "      <td>419</td>\n",
       "      <td>l</td>\n",
       "      <td>419</td>\n",
       "      <td>1.166960</td>\n",
       "      <td>114.031616</td>\n",
       "      <td>32.728819</td>\n",
       "      <td>100.0</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pdb  idx residue  res_idx       rsa        diam     gyrrad  pLDDTs  \\\n",
       "0    6wjl_G    1       s        1  0.974138  114.031616  32.728819   100.0   \n",
       "1    6wjl_G    2       c        2  0.247985  114.031616  32.728819   100.0   \n",
       "2    6wjl_G    3       a        3  0.435171  114.031616  32.728819   100.0   \n",
       "3    6wjl_G    4       e        4  0.379443  114.031616  32.728819   100.0   \n",
       "4    6wjl_G    5       t        5  0.013140  114.031616  32.728819   100.0   \n",
       "..      ...  ...     ...      ...       ...         ...        ...     ...   \n",
       "414  6wjl_G  415       l      415  0.495708  114.031616  32.728819   100.0   \n",
       "415  6wjl_G  416       g      416  0.135044  114.031616  32.728819   100.0   \n",
       "416  6wjl_G  417       h      417  0.583213  114.031616  32.728819   100.0   \n",
       "417  6wjl_G  418       d      418  0.329285  114.031616  32.728819   100.0   \n",
       "418  6wjl_G  419       l      419  1.166960  114.031616  32.728819   100.0   \n",
       "\n",
       "     length  struc_type  \n",
       "0       419           0  \n",
       "1       419           0  \n",
       "2       419           0  \n",
       "3       419           0  \n",
       "4       419           0  \n",
       "..      ...         ...  \n",
       "414     419           0  \n",
       "415     419           0  \n",
       "416     419           0  \n",
       "417     419           0  \n",
       "418     419           0  \n",
       "\n",
       "[419 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame for overview, but use the features above for training!\n",
    "df_stats = sample[\"df_stats\"]\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all: (7042, 536), y_all (7042,)\n"
     ]
    }
   ],
   "source": [
    "# Stack all features and targets to one big array\n",
    "X_all = np.concatenate([sample[\"X_arr\"] for sample in test_set])\n",
    "y_all = np.concatenate([sample[\"y_arr\"] for sample in test_set])\n",
    "print(f\"X_all: {X_all.shape}, y_all {y_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,\n",
       " array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot-encoding for amino acids sequence\n",
    "X_arr_sample = sample['X_arr']\n",
    "len(X_arr_sample[:,513]), X_arr_sample[:,512:532]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset (solved): 1123 PDBs\n",
      "Length of train dataset (af2): 1125 PDBs\n"
     ]
    }
   ],
   "source": [
    "# Training loading\n",
    "\n",
    "train_set = torch.load(\"bp3_train_seqs_solved/dataset.pt\")\n",
    "train_set_af2 = torch.load(\"bp3_train_seqs_af2/dataset.pt\")\n",
    "print(f\"Length of train dataset (solved): {len(train_set)} PDBs\")\n",
    "print(f\"Length of train dataset (af2): {len(train_set_af2)} PDBs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows from the train dataset (solved): 240092 instances\n",
      "Number of rows from the train dataset (af2): 240205 instances\n"
     ]
    }
   ],
   "source": [
    "# Counting total number of rows in the training data set\n",
    "\n",
    "train_objects = 0\n",
    "for i in range(len(train_set)):\n",
    "    sample_ = train_set[i]\n",
    "    train_objects = train_objects + sample_['X_arr'].shape[0]\n",
    "\n",
    "train_af2_objects = 0\n",
    "for i in range(len(train_set_af2)):\n",
    "    sample_ = train_set_af2[i]\n",
    "    train_af2_objects = train_af2_objects + sample_['X_arr'].shape[0]    \n",
    "\n",
    "print(f\"Number of rows from the train dataset (solved): {train_objects} instances\")\n",
    "print(f\"Number of rows from the train dataset (af2): {train_af2_objects} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: (114, 536)\n",
      "feature_columns: {'IF_tensor': range(0, 512), 'sequence': range(512, 532), 'pLDDTs': range(532, 533), 'lengths': range(533, 534), 'struc_type': range(534, 535), 'RSAs': range(535, 536)}\n",
      "targets: (114,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features: {sample_['X_arr'].shape}\")\n",
    "print(f\"feature_columns: {sample_['feature_idxs']}\")\n",
    "print(f\"targets: {sample_['y_arr'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of validation dataset (solved): 281 PDBs\n",
      "Length of validation dataset (af2): 281 PDBs\n"
     ]
    }
   ],
   "source": [
    "# Validation loading\n",
    "\n",
    "val_set = torch.load(\"bp3_valid_seqs_solved/dataset.pt\")\n",
    "val_set_af2 = torch.load(\"bp3_valid_seqs_af2/dataset.pt\")\n",
    "print(f\"Length of validation dataset (solved): {len(val_set)} PDBs\")\n",
    "print(f\"Length of validation dataset (af2): {len(val_set_af2)} PDBs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows from the validation dataset (solved): 59896 instances\n",
      "Number of rows from the validation dataset (af2): 59896 instances\n"
     ]
    }
   ],
   "source": [
    "# Counting total number of rows in the validation data set\n",
    "\n",
    "val_objects = 0\n",
    "for i in range(len(val_set)):\n",
    "    sample_ = val_set[i]\n",
    "    val_objects = val_objects + sample_['X_arr'].shape[0]\n",
    "\n",
    "val_af2_objects = 0\n",
    "for i in range(len(val_set_af2)):\n",
    "    sample_ = val_set_af2[i]\n",
    "    val_af2_objects = val_af2_objects + sample_['X_arr'].shape[0]    \n",
    "\n",
    "print(f\"Number of rows from the validation dataset (solved): {val_objects} instances\")\n",
    "print(f\"Number of rows from the validation dataset (af2): {val_af2_objects} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: (108, 536)\n",
      "feature_columns: {'IF_tensor': range(0, 512), 'sequence': range(512, 532), 'pLDDTs': range(532, 533), 'lengths': range(533, 534), 'struc_type': range(534, 535), 'RSAs': range(535, 536)}\n",
      "targets: (108,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features: {sample_['X_arr'].shape}\")\n",
    "print(f\"feature_columns: {sample_['feature_idxs']}\")\n",
    "print(f\"targets: {sample_['y_arr'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows from the testidation dataset (solved): 7042 instances\n",
      "Number of rows from the testidation dataset (af2): 7042 instances\n"
     ]
    }
   ],
   "source": [
    "# Counting total number of rows in the test data set\n",
    "\n",
    "test_objects = 0\n",
    "for i in range(len(test_set)):\n",
    "    sample_ = test_set[i]\n",
    "    test_objects = test_objects + sample_['X_arr'].shape[0]\n",
    "\n",
    "test_af2_objects = 0\n",
    "for i in range(len(test_set_af2)):\n",
    "    sample_ = test_set_af2[i]\n",
    "    test_af2_objects = test_af2_objects + sample_['X_arr'].shape[0]    \n",
    "\n",
    "print(f\"Number of rows from the testidation dataset (solved): {test_objects} instances\")\n",
    "print(f\"Number of rows from the testidation dataset (af2): {test_af2_objects} instances\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "98d96843242ea63546b941eb98e2ac308b462277a7c4020ae14ccf41d9fe0ade"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
